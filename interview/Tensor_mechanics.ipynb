{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29bb66b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7947d7",
   "metadata": {},
   "source": [
    "Question 1 - Tensor Mechanics\n",
    "\n",
    "What's wrong with the following pieces of code, fix and please explain the reasoning to the interviewer\n",
    "\n",
    "1A\n",
    "\n",
    "Perform a basic conv followed by a relu and another conv. What's wrong with the following code? Can you fix it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee91d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3,1,3,3) # B,C,H,W\n",
    "conv1 = torch.nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3)\n",
    "conv2 = torch.nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3)\n",
    "out = conv1(x)\n",
    "out = torch.relu(out)\n",
    "out = conv2(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b33d7c1",
   "metadata": {},
   "source": [
    "Solution:\n",
    "\n",
    "conv1: in_channels = 1\n",
    "\n",
    "conv2 in_channels = 6, kernel_size=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e491ff1a",
   "metadata": {},
   "source": [
    "1B\n",
    "\n",
    "Swap dimensions and reshape.Why doesn't this work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3245e5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3,4,5)\n",
    "x.transpose(1,2).view(15,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6c5091",
   "metadata": {},
   "source": [
    "Solution:\n",
    "\n",
    "x.reshape(15, 4)\n",
    "\n",
    "Because view requires the tensor to be stored in contiguous spot to display it, but does not change its storage\n",
    "\n",
    "transpose() can make a tensor non-contiguous\n",
    "\n",
    "reshape() = contiguous().view() by making sure the tensor is stored contiguously before viewing it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b128117",
   "metadata": {},
   "source": [
    "1C\n",
    "\n",
    "We have a large vector of points in 3D (x,y,z) and want to project it to a 2D screen in image space (u,v).\n",
    "\n",
    "The linear matrix equation is U = K * P * X\n",
    "\n",
    "where U the coordinates in image space, a Nx3 vector in homogenous coordinates (u,v,1).\n",
    "\n",
    "Simply ignore the last dimension if you are not familiar with homogenous coordinates.\n",
    "\n",
    "K is a 3x3 camera matrix \n",
    "\n",
    "P is a 3x4 projection matrix (it is a horizontal concat of a 3x3 rotation matrix R with a 3x1 translation vector T)\n",
    "\n",
    "X is a Nx4 vector point in 3d (again in homogenous coordinates) -> (x,y,z,1)\n",
    "\n",
    "Can you correct all the errors in the following project_camera function? Hint: you don't need to understand the theory behind camera projections. You can solve this question entirely based on fixing the tensor dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e5d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_camera(X,R,T,K):\n",
    "    P = torch.stack(R, T)\n",
    "    U = K * P * X\n",
    "    norm_U = torch.div(U, U[:,2])\n",
    "    return norm_U\n",
    "\n",
    "\n",
    "X = torch.rand(1000,4)\n",
    "R = torch.rand(3,3)\n",
    "T = torch.rand(3,1)\n",
    "K = torch.rand(3,3)\n",
    "result = project_camera(X,R,T,K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b266e5fc",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8cee12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.Size([1000, 3])\n"
     ]
    }
   ],
   "source": [
    "def project_camera(X,R,T,K):\n",
    "    P = torch.cat((R, T), dim=1)\n",
    "    # print(P.shape)\n",
    "    U = K @ P @ X.T\n",
    "    U = U.T\n",
    "    # print(U.shape)\n",
    "    norm_U = torch.div(U, U[:,[2]])\n",
    "    return norm_U\n",
    "\n",
    "\n",
    "X = torch.rand(1000,4)\n",
    "R = torch.rand(3,3)\n",
    "T = torch.rand(3,1)\n",
    "K = torch.rand(3,3)\n",
    "result = project_camera(X,R,T,K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d42a1",
   "metadata": {},
   "source": [
    "\n",
    "Question 2 - Debug a neural network\n",
    "\n",
    "2A. Debug the network\n",
    "\n",
    "Our intern, Bob, decided to build a neural network to find the location of a circle in an image and output the color. However, the network does not train properly nor output the correct results. Please help the intern debug it! You will be provided a dataset that generate images with a single circle in them with a color that can be in set of (red,green,blue).\n",
    "\n",
    "Dataset\n",
    "\n",
    "The CircleDataset generates blank canvases and draws a single circle with random radius, position and color. It also contains a visualization utility function to help visualize the dataset and predictions. For the purpose of this interview, you can safely assume this code is correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e07394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                            color: List[int],\n",
    "                            fill: bool = True) -> torch.Tensor:\n",
    "    blank_image = np.zeros((img_h,img_w,3), np.uint8)\n",
    "    coords = (cx-r,cy-r,cx+r,cy+r)\n",
    "    cv2.circle(blank_image, (int(cx), int(cy)), max(int(r),0), color, cv2.FILLED if fill else 3)\n",
    "    img_arr = torch.from_numpy(blank_image.transpose((2, 0, 1))).type(torch.float)\n",
    "    return img_arr\n",
    "\n",
    "  def _generate_data(self) -> Tuple[List,List,List]:\n",
    "    images, color_labels, pos_labels = [],[],[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421a37eb",
   "metadata": {},
   "source": [
    "Model\n",
    "\n",
    "The following code defines a simple model that can output a position, size, and color for a circle. You should NOT assume this code is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ff5f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CircleRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loc_loss = nn.MSELoss()\n",
    "        self.color_loss = nn.CrossEntropyLoss()\n",
    "        self.backbone = nn.Sequential()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "\n",
    "    def loss(self, loc, loc_label, color, color_label):\n",
    "        loc_loss = self.loc_loss(loc_label, loc_label)\n",
    "        color_loss = self.color_loss(color, color_label)\n",
    "        return loc_loss, color_loss\n",
    "\n",
    "cr = CircleRegressor()\n",
    "loc, color = cr.forward(torch.rand(1,3,100,100))\n",
    "print(loc, color)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d464c06a",
   "metadata": {},
   "source": [
    "Training code\n",
    "\n",
    "The following code is used to train and eval the provided model and dataset. After training for 10 epochs, Bob tries to visualize the eval outputs, the results show circle predictions that are almost always a single color and not well localized. The solid circles represent the ground truths and the circle outlines represent the predictions. Can you help Bob fix his model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc1e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    loss_color = []\n",
    "    for epoch in range(0, num_epochs):\n",
    "        for i, (inputs, loc_label, color_label) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            location, color = model.forward(inputs)\n",
    "            loc_loss, color_loss = model.compute_loss(location, loc_label, color, color_label)\n",
    "            total_loss = loc_loss*0.01 + color_loss\n",
    "            loss_loc.append(loc_loss.item())\n",
    "            loss_color.append(color_loss.item())\n",
    "            total_loss.backward()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0ef1da",
   "metadata": {},
   "source": [
    "2B. Follow-ups discussions (No coding required)\n",
    "\n",
    "CircleRegressor statically depends on the input image size, how can we make it dynamic? (ie: If you try to change the input image size from 100 to 99, the network will break.)\n",
    "\n",
    "What if we want to train the network on a batch of non-uniform sized images as input? For example we want to compose a batch of 2 images where image 1 has size 100 and image 2 has size 99.\n",
    "\n",
    "How do we train CircleRegressor in parallel on multiple GPUs or nodes?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

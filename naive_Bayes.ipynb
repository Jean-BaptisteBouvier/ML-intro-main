{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b56384ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "858a352e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'setosa': 0, 'versicolor': 1, 'virginica': 2}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = 'C:/Users/jeanb/Documents/Python Scripts/DiveIntoDL/data/'\n",
    "data = pd.read_csv(path + 'iris.csv')\n",
    "data.shape # 150, 5\n",
    "data.keys() # 'sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'\n",
    "features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "label = 'species'\n",
    "train_idx = list(range(0, 40)) + list(range(50, 90)) + list(range(100, 140))\n",
    "val_idx = list(range(40, 50)) + list(range(90, 100)) + list(range(140, 150))\n",
    "type(data['sepal_length'][val_idx])\n",
    "\n",
    "# from text labels to id labels\n",
    "label_idx = {}\n",
    "idx = 0\n",
    "for i in range(data.shape[0]):\n",
    "    label_name = data[label][i]\n",
    "    if label_name not in label_idx:\n",
    "        label_idx[label_name] = idx\n",
    "        idx += 1\n",
    "print(label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef351817",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.zeros((len(train_idx), len(features)))\n",
    "y_train = torch.zeros(len(train_idx))\n",
    "\n",
    "X_val = torch.zeros((len(val_idx), len(features)))\n",
    "y_val = torch.zeros(len(val_idx))\n",
    "\n",
    "for i, k in enumerate(features):\n",
    "    X_train[:, i] = torch.tensor(data[k][train_idx].values, dtype=torch.float32)\n",
    "    X_val[:, i] = torch.tensor(data[k][val_idx].values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "for i, j in enumerate(train_idx):\n",
    "    idx = label_idx[ data[label][j] ]\n",
    "    y_train[i] = torch.tensor(idx)\n",
    "\n",
    "for i, j in enumerate(val_idx):\n",
    "    idx = label_idx[ data[label][j] ]\n",
    "    y_val[i] = torch.tensor(idx)\n",
    "\n",
    "print(\"Training:\", X_train.shape, y_train.shape)\n",
    "print(\"Evaluation:\", X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "481a36aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 4\n",
      "Class probabilities: {0: 0.33333333333333354, 1: 0.33333333333333354, 2: 0.33333333333333354}\n",
      "0 torch.Size([40, 4])\n",
      "1 torch.Size([40, 4])\n",
      "2 torch.Size([40, 4])\n",
      "0 tensor([5.0375, 3.4400, 1.4625, 0.2325]) tensor([0.1311, 0.1327, 0.0296, 0.0099])\n",
      "1 tensor([6.0100, 2.7800, 4.3175, 1.3500]) tensor([0.2737, 0.1109, 0.2035, 0.0431])\n",
      "2 tensor([6.6225, 2.9600, 5.6075, 1.9900]) tensor([0.4679, 0.1132, 0.3453, 0.0743])\n"
     ]
    }
   ],
   "source": [
    "class NaiveBayes():\n",
    "    \"\"\"\n",
    "    Not multinomial or Bernoulli since features are not finite but continuous\n",
    "    \"\"\"\n",
    "    def __init__(self, X_train, y_train):\n",
    "        assert len(X_train.shape) == 2 \n",
    "        assert X_train.shape[0] == y_train.shape[0]\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.nb_features = X_train.shape[1]\n",
    "        print(f\"Number of features: {self.nb_features}\")\n",
    "\n",
    "        ### Calculate class probability in training dataset\n",
    "        self.class_probability = {}\n",
    "        N = len(y_train)\n",
    "        for i in range(N):\n",
    "            c = int(y_train[i].item())\n",
    "            if c in self.class_probability: # increase the count of class c by 1/total\n",
    "                self.class_probability[c] += 1./N\n",
    "            else: # create class c\n",
    "                self.class_probability[c] = 1./N\n",
    "        print(\"Class probabilities:\", self.class_probability)\n",
    "\n",
    "        ### Calculate feature mean and variance per class\n",
    "        self.features_per_class = {}\n",
    "        for c in self.class_probability.keys():\n",
    "            self.features_per_class[c] = [] # create the classes\n",
    "        for i in range(N):\n",
    "            c = int(y_train[i].item()) # class\n",
    "            self.features_per_class[c].append( X_train[i] )\n",
    "        \n",
    "        for c in self.features_per_class.keys():\n",
    "            self.features_per_class[c] = torch.vstack(self.features_per_class[c])\n",
    "            print(c, self.features_per_class[c].shape)\n",
    "\n",
    "        self.mean_feature_per_class = {}\n",
    "        self.variance_feature_per_class = {}\n",
    "        for c in self.features_per_class.keys():\n",
    "            self.mean_feature_per_class[c] = self.features_per_class[c].mean(dim=0)\n",
    "            self.variance_feature_per_class[c] = self.features_per_class[c].std(dim=0)**2\n",
    "            print(c, self.mean_feature_per_class[c], self.variance_feature_per_class[c])\n",
    "\n",
    "\n",
    "    def _Gaussian(self, mean, variance, xi):\n",
    "        \"\"\"Returns the Gaussian conditional probability  P( x_i | C )\n",
    "        Args: mean and variance of feature x_i in class C, xi value of feature x_i in the sample \"\"\"\n",
    "        return torch.exp(-(xi - mean)**2 / (2*variance)) / torch.sqrt(2*math.pi * variance)\n",
    "    \n",
    "    def _Gaussian_product(self, X, c):\n",
    "        \"\"\"Returns the product of the Gaussian probabilites for each feature xi of X knowing class c\"\"\"\n",
    "        assert len(X.shape) == 1\n",
    "        assert X.shape[0] == self.nb_features\n",
    "        prod = self.class_probability[c]\n",
    "        for i in range(X.shape[0]):\n",
    "            mean = self.mean_feature_per_class[c][i]\n",
    "            variance = self.variance_feature_per_class[c][i]\n",
    "            prod *= self._Gaussian(mean, variance, X[i])\n",
    "        return prod\n",
    "\n",
    "\n",
    "    def predict(self, X:torch.Tensor):\n",
    "        \"\"\"X: dim (batch, number_of_features)\"\"\"\n",
    "        assert len(X.shape) == 2 \n",
    "        assert X.shape[1] == self.nb_features\n",
    "\n",
    "        proba = []\n",
    "        classes = torch.zeros(X.shape[0])\n",
    "        for sample_id in range(X.shape[0]):\n",
    "            proba.append( [] )\n",
    "            for c in self.class_probability.keys():\n",
    "                proba[sample_id].append(self._Gaussian_product(X[sample_id], c))\n",
    "            proba[sample_id] = torch.hstack(proba[sample_id])\n",
    "            classes[sample_id] = torch.argmax(proba[sample_id]) # Maximum A Posteriori\n",
    "        print(proba)\n",
    "        return classes\n",
    "\n",
    "    \n",
    "model = NaiveBayes(X_train=X_train, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24838409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([3.2199e+00, 1.9678e-18, 1.6726e-23]), tensor([1.4864e+00, 7.8348e-18, 3.0087e-23]), tensor([1.1808e+00, 4.2286e-19, 3.1423e-24]), tensor([1.0775e+00, 6.3159e-18, 2.7884e-23]), tensor([2.9922e+00, 6.9194e-19, 7.0984e-24]), tensor([9.5790e-02, 1.2676e-15, 9.5040e-21]), tensor([1.3310e+00, 5.5624e-18, 4.0407e-23]), tensor([3.4167e+00, 1.0375e-17, 6.1412e-23]), tensor([2.3446e-01, 7.6173e-19, 3.6241e-24]), tensor([9.0727e-01, 1.5499e-18, 7.7728e-24]), tensor([1.6231e+00, 4.2186e-18, 4.3397e-23]), tensor([2.0610e+00, 1.7960e-17, 9.5237e-23]), tensor([5.6191e-01, 3.1635e-19, 1.7287e-24]), tensor([1.0150e-02, 2.3901e-22, 4.2850e-27]), tensor([3.6910e-02, 5.3501e-21, 2.4359e-25]), tensor([5.1775e-03, 3.0130e-19, 9.6920e-24]), tensor([1.5905e-01, 4.9912e-18, 8.1586e-23]), tensor([2.7003e+00, 2.5292e-17, 1.7420e-22]), tensor([1.3167e-01, 5.4059e-16, 4.5573e-21]), tensor([1.7523e+00, 9.8286e-18, 9.3317e-23]), tensor([8.2151e-01, 4.8948e-16, 2.1102e-21]), tensor([6.7887e-01, 2.4023e-16, 1.7066e-21]), tensor([4.1677e-02, 2.5785e-22, 9.0651e-27]), tensor([3.6020e-02, 3.7656e-13, 9.3169e-19]), tensor([1.1166e-01, 7.9043e-16, 2.7177e-21]), tensor([1.2332e+00, 1.8390e-16, 4.6424e-22]), tensor([6.5382e-01, 5.2930e-15, 1.8852e-20]), tensor([3.0827e+00, 1.1023e-17, 7.6369e-23]), tensor([2.9776e+00, 4.9303e-18, 3.5318e-23]), tensor([1.3404e+00, 2.8959e-17, 1.1637e-22]), tensor([1.3414e+00, 6.4065e-17, 2.0535e-22]), tensor([5.3533e-01, 4.4381e-15, 1.9641e-20]), tensor([2.6409e-01, 2.7240e-21, 7.4764e-26]), tensor([1.6631e-01, 6.4663e-21, 2.1128e-25]), tensor([9.0727e-01, 1.5499e-18, 7.7728e-24]), tensor([8.8415e-01, 3.3401e-19, 2.7717e-24]), tensor([9.8837e-01, 1.2923e-18, 1.5098e-23]), tensor([9.0727e-01, 1.5499e-18, 7.7728e-24]), tensor([2.3188e-01, 1.5206e-19, 1.0656e-24]), tensor([3.3843e+00, 1.4733e-17, 8.5940e-23]), tensor([0.0000, 0.0264, 0.0044]), tensor([0.0000, 0.1256, 0.0057]), tensor([0.0000, 0.0257, 0.0186]), tensor([0.0000e+00, 8.6352e-02, 8.3702e-06]), tensor([0.0000, 0.2110, 0.0092]), tensor([0.0000, 0.3880, 0.0006]), tensor([0.0000, 0.0443, 0.0134]), tensor([1.3246e-39, 5.3920e-04, 1.4705e-09]), tensor([0.0000, 0.2051, 0.0021]), tensor([0.0000e+00, 9.6038e-02, 2.7544e-05]), tensor([0.0000e+00, 2.4138e-04, 5.1516e-10]), tensor([0.0000, 0.3030, 0.0015]), tensor([0.0000e+00, 2.1380e-02, 3.8147e-07]), tensor([0.0000, 0.3241, 0.0049]), tensor([0.0000e+00, 9.7859e-02, 8.7392e-06]), tensor([0.0000, 0.1306, 0.0024]), tensor([0.0000, 0.2172, 0.0025]), tensor([0.0000e+00, 9.9655e-02, 4.1809e-06]), tensor([0.0000, 0.0754, 0.0005]), tensor([0.0000e+00, 8.4349e-02, 2.0860e-06]), tensor([0.0000, 0.0123, 0.0310]), tensor([0.0000e+00, 3.8604e-01, 1.4690e-04]), tensor([0.0000, 0.1043, 0.0077]), tensor([0.0000, 0.2737, 0.0007]), tensor([0.0000, 0.3566, 0.0007]), tensor([0.0000, 0.2105, 0.0026]), tensor([0.0000, 0.0906, 0.0074]), tensor([0.0000, 0.0134, 0.0752]), tensor([0.0000, 0.3442, 0.0050]), tensor([2.8026e-45, 1.7530e-02, 1.1415e-07]), tensor([0.0000e+00, 4.2081e-02, 6.3554e-07]), tensor([0.0000e+00, 1.5868e-02, 1.0466e-07]), tensor([0.0000e+00, 2.3286e-01, 1.8113e-05]), tensor([0.0000, 0.0541, 0.0278]), tensor([0.0000, 0.1497, 0.0015]), tensor([0.0000, 0.0408, 0.0039]), tensor([0.0000, 0.0735, 0.0126]), tensor([0.0000e+00, 1.5003e-01, 1.4697e-04]), tensor([0.0000e+00, 2.6472e-01, 1.1232e-04]), tensor([0.0000e+00, 1.7138e-01, 2.2507e-05]), tensor([0.0000e+00, 2.6972e-11, 1.7081e-02]), tensor([0.0000, 0.0031, 0.0538]), tensor([0.0000e+00, 1.4770e-07, 1.4518e-01]), tensor([0.0000, 0.0007, 0.1582]), tensor([0.0000e+00, 2.7660e-07, 1.5764e-01]), tensor([0.0000e+00, 1.6594e-11, 1.8142e-02]), tensor([0.0000, 0.0085, 0.0004]), tensor([0.0000e+00, 1.4182e-07, 5.4067e-02]), tensor([0.0000e+00, 6.5640e-05, 6.6452e-02]), tensor([0.0000e+00, 1.6492e-13, 3.2104e-03]), tensor([0.0000, 0.0002, 0.1203]), tensor([0.0000, 0.0011, 0.1331]), tensor([0.0000e+00, 6.2629e-06, 1.9935e-01]), tensor([0.0000, 0.0007, 0.0212]), tensor([0.0000e+00, 2.9333e-07, 2.2050e-02]), tensor([0.0000e+00, 4.6617e-07, 7.6920e-02]), tensor([0.0000, 0.0008, 0.1726]), tensor([0.0000e+00, 5.1599e-15, 3.8775e-04]), tensor([0.0000e+00, 5.2488e-15, 1.7425e-03]), tensor([0.0000, 0.0278, 0.0014]), tensor([0.0000e+00, 1.4177e-08, 8.4597e-02]), tensor([0.0000, 0.0012, 0.0324]), tensor([0.0000e+00, 1.8273e-11, 1.0502e-02]), tensor([0.0000, 0.0179, 0.0578]), tensor([0.0000e+00, 8.5519e-07, 1.2437e-01]), tensor([0.0000e+00, 1.6004e-06, 7.8036e-02]), tensor([0.0000, 0.0260, 0.0516]), tensor([0.0000, 0.0170, 0.0645]), tensor([0.0000e+00, 1.0051e-05, 1.7884e-01]), tensor([0.0000e+00, 6.8548e-05, 5.4205e-02]), tensor([0.0000e+00, 1.8444e-07, 7.1472e-02]), tensor([0.0000e+00, 1.2191e-12, 7.1490e-04]), tensor([0.0000e+00, 1.5691e-06, 1.4418e-01]), tensor([0.0000, 0.0758, 0.0250]), tensor([0.0000, 0.0075, 0.0093]), tensor([0.0000e+00, 2.5961e-11, 2.4243e-02]), tensor([0.0000e+00, 3.8192e-09, 2.8107e-02]), tensor([0.0000, 0.0008, 0.1537]), tensor([0.0000, 0.0224, 0.0459]), tensor([0.0000e+00, 6.3008e-06, 1.6756e-01])]\n",
      "Training Accuracy: 95.83%\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the training set\n",
    "predictions = model.predict(X_train)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (predictions == y_train).float().mean()\n",
    "print(f\"Training Accuracy: {accuracy.item() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef9fe139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1.8638e+00, 4.1446e-18, 3.6280e-23]), tensor([4.7186e-03, 1.5207e-18, 2.5977e-24]), tensor([3.8706e-01, 8.5371e-20, 8.3217e-25]), tensor([2.9869e-03, 1.4968e-13, 6.7654e-19]), tensor([2.1662e-02, 1.7169e-14, 7.8489e-20]), tensor([1.0804e+00, 6.5917e-17, 2.1455e-22]), tensor([1.5545e+00, 2.9786e-18, 2.9013e-23]), tensor([1.2852e+00, 1.1057e-18, 7.0733e-24]), tensor([2.0599e+00, 3.3148e-18, 3.3064e-23]), tensor([3.0606e+00, 4.2403e-18, 2.6000e-23]), tensor([0.0000e+00, 2.1064e-01, 6.0928e-05]), tensor([0.0000, 0.3274, 0.0037]), tensor([0.0000e+00, 2.4808e-01, 2.2261e-05]), tensor([6.2287e-40, 5.3887e-04, 1.2266e-09]), tensor([0.0000e+00, 3.4736e-01, 1.2799e-04]), tensor([0.0000e+00, 2.5991e-01, 7.7842e-05]), tensor([0.0000e+00, 3.8215e-01, 2.0901e-04]), tensor([0.0000, 0.4408, 0.0006]), tensor([2.1472e-35, 5.4523e-04, 1.9356e-09]), tensor([0.0000e+00, 3.7490e-01, 1.2436e-04]), tensor([0.0000e+00, 6.6577e-09, 6.7294e-02]), tensor([0.0000e+00, 4.8130e-07, 6.9768e-02]), tensor([0.0000, 0.0031, 0.0538]), tensor([0.0000e+00, 4.4893e-09, 7.9442e-02]), tensor([0.0000e+00, 1.2617e-10, 2.3415e-02]), tensor([0.0000e+00, 7.2645e-07, 9.3038e-02]), tensor([0.0000, 0.0030, 0.0447]), tensor([0.0000, 0.0003, 0.1759]), tensor([0.0000e+00, 1.3579e-07, 3.9605e-02]), tensor([0.0000, 0.0086, 0.0703])]\n",
      "Validation Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the validation set\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (predictions == y_val).float().mean()\n",
    "print(f\"Validation Accuracy: {accuracy.item() * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dino-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
